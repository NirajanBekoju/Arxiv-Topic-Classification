{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXV4AVZqZHta",
        "outputId": "de0deba6-a052-4080-f082-213cdaebfcd9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons\n",
        "!pip install Keras-Preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDbEdyaYaB8o",
        "outputId": "1934486a-5cf2-4e7b-e97c-ba3dde19c33f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Collecting Keras-Preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "URgAqt1CZDpr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import tensorflow_addons as tfa\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_PATH = \"/content/drive/MyDrive/Colab Notebooks/Arxiv Topic Classification/first 1 million/\""
      ],
      "metadata": {
        "id": "zNieXOG8Z-x1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(FILE_PATH + \"test_data.csv\")"
      ],
      "metadata": {
        "id": "Ar_L3ZvkaTT2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "OnB9ZLoTbqC6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "metadata": {
        "id": "yJ-kSF01baq-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = FILE_PATH + \"model2.h5\"\n",
        "custom_objects = {\"TransformerBlock\": TransformerBlock,\n",
        "                  \"TokenAndPositionEmbedding\": TokenAndPositionEmbedding,\n",
        "                  \"HammingLoss\" : tfa.metrics.HammingLoss(mode='multilabel')}\n",
        "loaded_model = load_model(model_path, custom_objects=custom_objects)"
      ],
      "metadata": {
        "id": "5dNBZc80aUvQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_word_collection = stopwords.words('english')\n",
        "\n",
        "import string\n",
        "\n",
        "def text_preprocess(text):\n",
        "  # Remove all punctuations\n",
        "  text = ''.join(c for c in text if c not in string.punctuation)\n",
        "\n",
        "  # Remove all numbers and words containing numbers\n",
        "  text = re.sub(r'\\w*\\d\\w*', ' ', text).strip()\n",
        "\n",
        "  # Changes to lower case\n",
        "  text = text.lower()\n",
        "\n",
        "  # Remove all stop words\n",
        "  text = ' '. join(word for word in text.split() if word not in stop_word_collection)\n",
        "\n",
        "  # Stemming of all words\n",
        "  text = [ps.stem(word) for word in text.split()]\n",
        "  text = ' '.join(text)\n",
        "  return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "win8FeztdOso",
        "outputId": "fe6de514-9f7a-41e4-f6f0-8efb5c606b21"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, tokenizer, labels_list, preprocessed = False, top_k = 3):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    text: input text\n",
        "    tokenizer: word tokenizer for the text\n",
        "    labels_list: list of all the labels we have in our data\n",
        "    preprocessed: Whether the input data is already processed or not\n",
        "    top_k: no. of labels to be returned along with their probabililties\n",
        "\n",
        "  Output:\n",
        "    top_k no. of labels along with their corresponding probabilities\n",
        "  \"\"\"\n",
        "  if not preprocessed:\n",
        "    text = text_preprocess(text)\n",
        "  text_sequence = tokenizer.texts_to_sequences([text])\n",
        "  text_padded = pad_sequences(text_sequence, maxlen = MAX_PAD_LENGTH, padding = \"post\", truncating = \"post\")\n",
        "  predictions = list(loaded_model.predict(text_padded)[0])\n",
        "  # get the indices of top three values\n",
        "  top_indices = [i for i, val in sorted(enumerate(predictions), key=lambda x: x[1], reverse=True)[:top_k]]\n",
        "  # Create a new list with 1s for top three indices and 0s for the rest\n",
        "  prediction_list = [1 if i in top_indices else 0 for i in range(len(predictions))]\n",
        "\n",
        "  # For top k labels, the label name and their corresponding probabilities are provided\n",
        "  labels = [labels_list[i] for i in range(len(labels_list)) if prediction_list[i] == 1]\n",
        "  prediction_probabilities = [predictions[i] for i in range(len(predictions)) if prediction_list[i] == 1]\n",
        "  sorted_data = sorted(zip(labels, prediction_probabilities), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  return sorted_data"
      ],
      "metadata": {
        "id": "zo6hHA5Vdf1p"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the labels list and the tokenizer\n",
        "# Step 2: Predict the labels\n",
        "with open(FILE_PATH + 'label_name.pkl', 'rb') as handle:\n",
        "  labels_list = pickle.load(handle)\n",
        "with open(FILE_PATH + 'tokenizer.pkl', 'rb') as handle:\n",
        "  tokenizer = pickle.load(handle)\n",
        "\n",
        "text = X_test[0]\n",
        "predict(text, tokenizer, labels_list = labels_list, preprocessed = True, top_k = 5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQi5QFr8iwUx",
        "outputId": "c14c7ae9-13a3-4249-d6c0-faf16156804d"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('hep-ph', 0.9601804),\n",
              " ('hep-ex', 0.22531293),\n",
              " ('astro-ph', 0.19884947),\n",
              " ('astro-ph.HE', 0.055537507),\n",
              " ('nucl-th', 0.020627443)]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"This study significantly concentrates on cryogenic InP HEMT high-frequency circuit analysis using quantum theory to find how the transistor nonlinearity can affect the quantum correlation of the modes generated. Firstly, the total Hamiltonian of the circuit is derived, and the dynamic equation of the motion contributed is examined using the Heisenberg-Langevin equation. Using the nonlinear Hamiltonian, some components are attached to the intrinsic internal circuit of InP HEMT to address the circuit characteristics fully. The components attached are arisen due to the nonlinearity effects. As a result, the theoretical calculations show that the states generated in the circuit are mixed, and no pure state is produced. Accordingly, the modified circuit generates the two-mode squeezed thermal state, which means one can focus on calculating the Gaussian quantum discord to evaluate quantum correlation. It is also found that the nonlinearity factors (addressed as the nonlinear components in the circuit) can intensely influence the squeezed thermal state by which the quantum discord is changed. Finally, as the primary point, it is concluded that although it is possible to enhance the quantum correlation between modes by engineering the nonlinear components; however, attaining quantum discord greater than unity, \"\"\"\n",
        "predict(text, tokenizer, labels_list = labels_list, preprocessed = False, top_k = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wjymkiapdEh",
        "outputId": "bc0a0dea-561f-4b2b-90fc-5a92392dfbe0"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('quant-ph', 0.93055),\n",
              " ('cond-mat.mes-hall', 0.20567559),\n",
              " ('physics.optics', 0.07040421),\n",
              " ('cond-mat.other', 0.057682544),\n",
              " ('cond-mat.stat-mech', 0.03836287)]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_name = list(test_data.columns)\n",
        "label_name.pop(0)\n",
        "X_test, y_test = test_data[\"text\"], test_data[label_name]"
      ],
      "metadata": {
        "id": "fvhtTUm-ll1a"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Explanation steps of the prediction function\n",
        "MAX_PAD_LENGTH = 210\n",
        "text = \"quantum physics is difficult.\"\n",
        "text = text_preprocess(text)\n",
        "print(text)\n",
        "text_sequence = tokenizer.texts_to_sequences([text])\n",
        "print(text_sequence)\n",
        "text_padded = pad_sequences(text_sequence, maxlen = MAX_PAD_LENGTH, padding = \"post\", truncating = \"post\")\n",
        "print(text_padded)\n",
        "print(\"Prediction: \")\n",
        "print(loaded_model.predict(text_padded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTuaDa9UhpAS",
        "outputId": "46c957fa-863b-4c97-9243-db3f60daf0bb"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quantum physic difficult\n",
            "[[23, 131, 1282]]\n",
            "[[  23  131 1282    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "Prediction: \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "[[2.05898599e-04 9.60573452e-05 1.35462471e-06 1.74658253e-05\n",
            "  6.48751229e-05 3.80384481e-05 3.15886718e-05 2.65317824e-04\n",
            "  9.07444116e-03 8.21205880e-03 1.27979387e-02 5.31439786e-04\n",
            "  3.01197506e-05 3.71160032e-03 8.94839503e-03 2.55295634e-03\n",
            "  1.51876840e-04 8.12345479e-06 2.12248502e-04 3.50559349e-05\n",
            "  1.09763687e-05 3.99817873e-05 9.59841855e-05 1.74959987e-05\n",
            "  7.27240549e-05 3.58071429e-06 2.07530647e-05 2.54181705e-05\n",
            "  8.11341568e-04 6.88950022e-05 1.13206741e-04 2.31806858e-04\n",
            "  7.08026782e-05 2.40556292e-05 4.26342422e-06 1.25983534e-05\n",
            "  1.20351933e-05 1.56044436e-03 9.04263288e-06 1.83702877e-03\n",
            "  4.07816788e-06 1.16653137e-05 5.74457808e-04 1.37008392e-04\n",
            "  1.51937656e-05 2.74442773e-05 6.30286057e-04 1.94438835e-05\n",
            "  3.03597972e-05 2.72919599e-04 3.04210130e-06 3.19244992e-03\n",
            "  1.80939442e-05 1.07827545e-04 1.72240980e-05 1.10147739e-04\n",
            "  1.51829715e-06 1.35183946e-05 2.33627293e-06 2.73929322e-06\n",
            "  3.57534350e-06 3.47178539e-05 5.75374588e-06 1.35249058e-02\n",
            "  1.39553426e-02 9.00146738e-03 1.18109390e-01 1.90391198e-01\n",
            "  2.97729522e-01 2.14080629e-03 6.96680648e-03 1.77722285e-03\n",
            "  6.66624168e-04 8.37389100e-03 2.62934659e-02 5.41950483e-03\n",
            "  2.19831243e-03 2.82285432e-03 6.19182130e-04 5.29264146e-03\n",
            "  4.55314759e-03 1.47358835e-04 6.80333236e-03 1.06087129e-03\n",
            "  1.16957482e-02 1.70810567e-03 9.18864913e-04 3.28105339e-03\n",
            "  4.03859071e-04 2.92656869e-01 2.55057967e-04 4.91587725e-03\n",
            "  3.67300468e-03 6.77698757e-04 2.98049720e-03 1.05459370e-01\n",
            "  4.90567014e-02 2.45603025e-02 5.34069957e-04 1.03567285e-03\n",
            "  1.23469552e-04 1.32781861e-04 1.49940883e-04 4.41672419e-05\n",
            "  1.81636700e-04 9.12984274e-03 3.68710840e-03 1.29868984e-02\n",
            "  1.63896312e-03 1.60338902e-06 4.86192585e-05 5.43980394e-04\n",
            "  5.50789805e-03 1.01571359e-05 1.34375610e-03 4.39492520e-03\n",
            "  2.62153684e-03 1.69164769e-03 7.78683042e-03 1.34357515e-05\n",
            "  1.35150000e-01 6.67558197e-06 8.31110626e-02 2.30339749e-04\n",
            "  1.11709833e-05 4.26082173e-03 7.17932853e-05 1.26770604e-02\n",
            "  1.08233944e-04 2.25471013e-05 1.81194412e-06 1.24032169e-06\n",
            "  1.87795109e-07 2.95463656e-06 2.96833023e-05 2.51304791e-05\n",
            "  1.98565726e-06 9.64249375e-06 3.69556545e-07 6.19451043e-07\n",
            "  6.29886563e-05 6.35971082e-05 5.74358310e-05 6.50214133e-05\n",
            "  1.51541872e-05 1.51872464e-05 1.30928765e-05 2.85864894e-06\n",
            "  1.57293164e-06 2.67070919e-01 1.22936559e-04 3.57350546e-05\n",
            "  1.72051859e-05 1.31617935e-05 4.27926643e-05 1.35096183e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2nlqMK7ojJoM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}